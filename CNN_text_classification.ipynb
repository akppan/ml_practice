{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN_text_classification.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMmUQkGFj8OplBV7DP1xYFf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/akppan/ml_practice/blob/master/CNN_text_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iCn4bUqJFRjf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MnGI2T6qGxWK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import nltk\n",
        "from nltk import tokenize"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "474V8dj8Gx1k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n1Bag_mwGyR5",
        "colab_type": "code",
        "outputId": "ef42c3e8-bbdf-4286-f61a-4caf5de7c01d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,Embedding,Conv1D,Dropout,MaxPooling1D"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qhLiOLf5JGBR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import optimizers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o9ckLvOiGyzG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ltFm0lRG2ln",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = pd.read_csv('/content/SMSSpamCollection.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wGU6kPM3HIjv",
        "colab_type": "code",
        "outputId": "3b7d3493-4218-40f3-f734-11d09218f1bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        }
      },
      "source": [
        "dataset.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Type</th>\n",
              "      <th>Message</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Type                                            Message\n",
              "0   ham  Go until jurong point, crazy.. Available only ...\n",
              "1   ham                      Ok lar... Joking wif u oni...\n",
              "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
              "3   ham  U dun say so early hor... U c already then say...\n",
              "4   ham  Nah I don't think he goes to usf, he lives aro..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3QAZNdLBHXxV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tags = dataset['Type']\n",
        "texts = dataset['Message']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3NiZzjiAHXsI",
        "colab_type": "code",
        "outputId": "38324cb2-84cd-484c-fc2b-2bf35d7cb7b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        }
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation\n",
        "from keras.layers import Embedding\n",
        "from keras.layers import Conv1D, GlobalMaxPooling1D\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing import sequence\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras import metrics\n",
        "\n",
        "num_max = 1000\n",
        "le = LabelEncoder()\n",
        "tags = le.fit_transform(tags)\n",
        "#print(tags)\n",
        "# tok = Tokenizer()\n",
        "tok = Tokenizer(num_words=num_max)\n",
        "print(tok.fit_on_texts(texts))\n",
        "# print((tok.fit_on_texts(texts)).shape)\n",
        "mat_texts = tok.texts_to_matrix(texts,mode='count')\n",
        "print(mat_texts)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train,x_test,y_train,y_test = train_test_split(texts,tags, test_size = 0.3)\n",
        "mat_texts_tr = tok.texts_to_matrix(x_train,mode='count')\n",
        "print(mat_texts_tr)\n",
        "print(mat_texts_tr.shape)\n",
        "mat_texts_tst = tok.texts_to_matrix(x_test,mode='count')\n",
        "\n",
        "max_len = 100\n",
        "x_train = tok.texts_to_sequences(x_train)\n",
        "x_test = tok.texts_to_sequences(x_test)\n",
        "cnn_texts_mat = sequence.pad_sequences(x_train,maxlen=max_len)\n",
        "max_len = 100\n",
        "cnn_texts_mat_tst = sequence.pad_sequences(x_test,maxlen=max_len)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "None\n",
            "[[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 3. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 1. 1. ... 0. 0. 0.]\n",
            " [0. 0. 1. ... 0. 0. 0.]]\n",
            "[[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 3. 2. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 2. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 2. 2. ... 0. 0. 0.]]\n",
            "(3901, 1000)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zg5TfJ8lHXnB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_cnn_model_v1():   \n",
        "    model = Sequential()\n",
        "    model.add(Embedding(1000,20,input_length=max_len))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Conv1D(64,3,padding='valid',activation='relu',strides=1))\n",
        "    model.add(GlobalMaxPooling1D())\n",
        "    model.add(Dense(256))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Dense(1))\n",
        "    model.add(Activation('sigmoid'))\n",
        "    model.summary()\n",
        "    model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['acc',metrics.binary_accuracy])\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CSJBmRqKOFNq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def check_model(model,xtr,ytr,xts,yts):\n",
        "    model.fit(xtr,ytr,batch_size=32,epochs=10,verbose=1)\n",
        "    print(' ')\n",
        "    model.evaluate(xts,yts)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XWvAuqfROKTL",
        "colab_type": "code",
        "outputId": "4bf40fbc-74e9-4a4f-c2de-d2c8c7425ec1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 820
        }
      },
      "source": [
        "m1 = get_cnn_model_v1()\n",
        "check_model(m,cnn_texts_mat,y_train,cnn_texts_mat_tst,y_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_7 (Embedding)      (None, 100, 20)           20000     \n",
            "_________________________________________________________________\n",
            "dropout_17 (Dropout)         (None, 100, 20)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_6 (Conv1D)            (None, 98, 64)            3904      \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d_6 (Glob (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_21 (Dense)             (None, 256)               16640     \n",
            "_________________________________________________________________\n",
            "dropout_18 (Dropout)         (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "activation_11 (Activation)   (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_22 (Dense)             (None, 1)                 257       \n",
            "_________________________________________________________________\n",
            "activation_12 (Activation)   (None, 1)                 0         \n",
            "=================================================================\n",
            "Total params: 40,801\n",
            "Trainable params: 40,801\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "3901/3901 [==============================] - 3s 826us/step - loss: 0.0017 - acc: 0.9997 - binary_accuracy: 0.9997\n",
            "Epoch 2/10\n",
            "3901/3901 [==============================] - 2s 579us/step - loss: 0.0017 - acc: 0.9997 - binary_accuracy: 0.9997\n",
            "Epoch 3/10\n",
            "3901/3901 [==============================] - 2s 583us/step - loss: 0.0020 - acc: 0.9997 - binary_accuracy: 0.9997\n",
            "Epoch 4/10\n",
            "3901/3901 [==============================] - 2s 577us/step - loss: 0.0016 - acc: 0.9997 - binary_accuracy: 0.9997\n",
            "Epoch 5/10\n",
            "3901/3901 [==============================] - 2s 573us/step - loss: 0.0018 - acc: 0.9995 - binary_accuracy: 0.9995\n",
            "Epoch 6/10\n",
            "3901/3901 [==============================] - 2s 585us/step - loss: 0.0018 - acc: 0.9997 - binary_accuracy: 0.9997\n",
            "Epoch 7/10\n",
            "3901/3901 [==============================] - 2s 569us/step - loss: 0.0015 - acc: 0.9997 - binary_accuracy: 0.9997\n",
            "Epoch 8/10\n",
            "3901/3901 [==============================] - 2s 565us/step - loss: 0.0018 - acc: 0.9995 - binary_accuracy: 0.9995\n",
            "Epoch 9/10\n",
            "3901/3901 [==============================] - 2s 566us/step - loss: 0.0015 - acc: 0.9997 - binary_accuracy: 0.9997\n",
            "Epoch 10/10\n",
            "3901/3901 [==============================] - 2s 567us/step - loss: 0.0015 - acc: 0.9997 - binary_accuracy: 0.9997\n",
            " \n",
            "1673/1673 [==============================] - 0s 124us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LuRCyyL5OR8l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_cnn_model_v2():   \n",
        "    model = Sequential()\n",
        "    model.add(Embedding(1000,50,input_length=max_len))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Conv1D(64,3,padding='valid',activation='relu',strides=1))\n",
        "    model.add(GlobalMaxPooling1D())\n",
        "    model.add(Dense(256))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Dense(1))\n",
        "    model.add(Activation('sigmoid'))\n",
        "    model.summary()\n",
        "    model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['acc',metrics.binary_accuracy])\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x7TMRcHeMEhx",
        "colab_type": "code",
        "outputId": "00b658b0-4c1a-4d67-8eb7-8ded565673a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 820
        }
      },
      "source": [
        "m2 = get_cnn_model_v2()\n",
        "check_model(m,cnn_texts_mat,y_train,cnn_texts_mat_tst ,y_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_11\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_8 (Embedding)      (None, 100, 50)           50000     \n",
            "_________________________________________________________________\n",
            "dropout_19 (Dropout)         (None, 100, 50)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_7 (Conv1D)            (None, 98, 64)            9664      \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d_7 (Glob (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_23 (Dense)             (None, 256)               16640     \n",
            "_________________________________________________________________\n",
            "dropout_20 (Dropout)         (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "activation_13 (Activation)   (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_24 (Dense)             (None, 1)                 257       \n",
            "_________________________________________________________________\n",
            "activation_14 (Activation)   (None, 1)                 0         \n",
            "=================================================================\n",
            "Total params: 76,561\n",
            "Trainable params: 76,561\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "3901/3901 [==============================] - 3s 814us/step - loss: 0.0012 - acc: 0.9997 - binary_accuracy: 0.9997\n",
            "Epoch 2/10\n",
            "3901/3901 [==============================] - 2s 579us/step - loss: 0.0015 - acc: 0.9997 - binary_accuracy: 0.9997\n",
            "Epoch 3/10\n",
            "3901/3901 [==============================] - 2s 554us/step - loss: 0.0015 - acc: 0.9997 - binary_accuracy: 0.9997\n",
            "Epoch 4/10\n",
            "3901/3901 [==============================] - 2s 615us/step - loss: 0.0014 - acc: 0.9997 - binary_accuracy: 0.9997\n",
            "Epoch 5/10\n",
            "3901/3901 [==============================] - 2s 604us/step - loss: 0.0013 - acc: 0.9997 - binary_accuracy: 0.9997\n",
            "Epoch 6/10\n",
            "3901/3901 [==============================] - 2s 585us/step - loss: 0.0012 - acc: 0.9997 - binary_accuracy: 0.9997\n",
            "Epoch 7/10\n",
            "3901/3901 [==============================] - 2s 586us/step - loss: 0.0013 - acc: 0.9997 - binary_accuracy: 0.9997\n",
            "Epoch 8/10\n",
            "3901/3901 [==============================] - 2s 553us/step - loss: 0.0015 - acc: 0.9997 - binary_accuracy: 0.9997\n",
            "Epoch 9/10\n",
            "3901/3901 [==============================] - 2s 548us/step - loss: 0.0012 - acc: 0.9997 - binary_accuracy: 0.9997\n",
            "Epoch 10/10\n",
            "3901/3901 [==============================] - 2s 551us/step - loss: 0.0014 - acc: 0.9997 - binary_accuracy: 0.9997\n",
            " \n",
            "1673/1673 [==============================] - 0s 129us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p2ZWRNXhMHCe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers import LSTM\n",
        "\n",
        "max_features = 5000\n",
        "maxlen = 400\n",
        "batch_size = 32\n",
        "embedding_dims = 50\n",
        "filters = 250\n",
        "kernel_size = 3\n",
        "hidden_dims = 250\n",
        "epochs = 2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ieIcmi_MQML",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_cnn_model_v4():    \n",
        "    model = Sequential()\n",
        "    model.add(Embedding(max_features, 128))\n",
        "    model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2,activation='relu'))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['acc',metrics.binary_accuracy])\n",
        "\n",
        "    print('Train...')\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2fQr7E5TMURs",
        "colab_type": "code",
        "outputId": "1c29d12c-cbf6-4523-8bab-8b7c5fb5f310",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401
        }
      },
      "source": [
        "m3 = get_cnn_model_v4()\n",
        "check_model(m,cnn_texts_mat,y_train,cnn_texts_mat_tst ,y_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train...\n",
            "Epoch 1/10\n",
            "3901/3901 [==============================] - 3s 788us/step - loss: 0.0013 - acc: 0.9997 - binary_accuracy: 0.9997\n",
            "Epoch 2/10\n",
            "3901/3901 [==============================] - 2s 601us/step - loss: 0.0014 - acc: 0.9997 - binary_accuracy: 0.9997\n",
            "Epoch 3/10\n",
            "3901/3901 [==============================] - 2s 545us/step - loss: 0.0012 - acc: 0.9997 - binary_accuracy: 0.9997\n",
            "Epoch 4/10\n",
            "3901/3901 [==============================] - 2s 552us/step - loss: 0.0013 - acc: 0.9997 - binary_accuracy: 0.9997\n",
            "Epoch 5/10\n",
            "3901/3901 [==============================] - 2s 552us/step - loss: 0.0011 - acc: 0.9997 - binary_accuracy: 0.9997\n",
            "Epoch 6/10\n",
            "3901/3901 [==============================] - 2s 618us/step - loss: 0.0013 - acc: 0.9997 - binary_accuracy: 0.9997\n",
            "Epoch 7/10\n",
            "3901/3901 [==============================] - 2s 620us/step - loss: 0.0012 - acc: 0.9997 - binary_accuracy: 0.9997\n",
            "Epoch 8/10\n",
            "3901/3901 [==============================] - 2s 627us/step - loss: 0.0011 - acc: 0.9997 - binary_accuracy: 0.9997\n",
            "Epoch 9/10\n",
            "3901/3901 [==============================] - 2s 615us/step - loss: 0.0013 - acc: 0.9997 - binary_accuracy: 0.9997\n",
            "Epoch 10/10\n",
            "3901/3901 [==============================] - 2s 617us/step - loss: 0.0012 - acc: 0.9997 - binary_accuracy: 0.9997\n",
            " \n",
            "1673/1673 [==============================] - 0s 153us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OIrGTMDwMYVt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_simple_model():\n",
        "    model = Sequential()\n",
        "    model.add(Dense(512, activation='relu', input_shape=(num_max,)))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(256, activation='relu'))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    model.summary()\n",
        "    model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['acc',metrics.binary_accuracy])\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QByraiLDQIhX",
        "colab_type": "code",
        "outputId": "ec7d3557-b367-49b7-b3a8-3cf10fc5473f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 640
        }
      },
      "source": [
        "m4 = get_simple_model()\n",
        "check_model(m,mat_texts_tr,y_train,mat_texts_tst,y_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_14\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_28 (Dense)             (None, 512)               512512    \n",
            "_________________________________________________________________\n",
            "dropout_23 (Dropout)         (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_29 (Dense)             (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "dropout_24 (Dropout)         (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_30 (Dense)             (None, 1)                 257       \n",
            "=================================================================\n",
            "Total params: 644,097\n",
            "Trainable params: 644,097\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-66-f2c612ecbcec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mm4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_simple_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcheck_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmat_texts_tr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmat_texts_tst\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-48-84296ff8f415>\u001b[0m in \u001b[0;36mcheck_model\u001b[0;34m(model, xtr, ytr, xts, yts)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcheck_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mxtr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mytr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mxts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxtr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mytr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1087\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1088\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1089\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1090\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1091\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    755\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 757\u001b[0;31m             exception_prefix='input')\n\u001b[0m\u001b[1;32m    758\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    759\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    139\u001b[0m                             \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m                             str(data_shape))\n\u001b[0m\u001b[1;32m    142\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected embedding_10_input to have shape (100,) but got array with shape (1000,)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aiR-4qNyQMcr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_cnn_model_v3():    \n",
        "    model = Sequential()\n",
        "    model.add(Embedding(1000,20,input_length=max_len))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Conv1D(256,3,padding='valid',activation='relu',strides=1))\n",
        "    model.add(GlobalMaxPooling1D())\n",
        "    model.add(Dense(256))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Dense(1))\n",
        "    model.add(Activation('sigmoid'))\n",
        "    model.summary()\n",
        "    model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['acc',metrics.binary_accuracy])\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e9N8ZdxRRhmB",
        "colab_type": "code",
        "outputId": "44a0196e-0e64-4f92-8518-81608c4165e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 771
        }
      },
      "source": [
        "m = get_cnn_model_v3()\n",
        "check_model(m,cnn_texts_mat,y_train,cnn_texts_mat_tst ,y_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_2 (Embedding)      (None, 100, 20)           20000     \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 100, 20)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 98, 256)           15616     \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d_2 (Glob (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 1)                 257       \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 1)                 0         \n",
            "=================================================================\n",
            "Total params: 101,665\n",
            "Trainable params: 101,665\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-61-c9d187b93279>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_cnn_model_v3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcheck_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcnn_texts_mat\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcnn_texts_mat_tst\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-59-84296ff8f415>\u001b[0m in \u001b[0;36mcheck_model\u001b[0;34m(model, xtr, ytr, xts, yts)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcheck_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mxtr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mytr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mxts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxtr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mytr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1176\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1178\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m     def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    202\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2977\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2979\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2980\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2981\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2915\u001b[0m                 array_vals.append(\n\u001b[1;32m   2916\u001b[0m                     np.asarray(value,\n\u001b[0;32m-> 2917\u001b[0;31m                                dtype=tf.as_dtype(tensor.dtype).as_numpy_dtype))\n\u001b[0m\u001b[1;32m   2918\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2919\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/core/_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \"\"\"\n\u001b[0;32m---> 85\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'ham'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IWYf3YGPXdYj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sieeMtlNXdd9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yXjmkGQfXdj4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "import itertools"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zx-cpyQvXdp2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clean_data(message):\n",
        "    # removing web links\n",
        "    if(isinstance(message, str)):\n",
        "        m = [ re.sub(r'http\\S+', '', message.lower())]\n",
        "        ## removing words like goooood and pooooor to good and poor\n",
        "        m = [''.join(''.join(m)[:2] for _, m in itertools.groupby(m[0]))]\n",
        "        ## removing appostophes\n",
        "        m = [remove_appostophes(m[0])]\n",
        "        ## removing punctuations from the code \n",
        "        m = [remove_punctuations(m[0])]\n",
        "        return m[0]\n",
        "    else:\n",
        "        return message\n",
        "\n",
        "def remove_appostophes(msg):\n",
        "    if(isinstance(msg, str)):\n",
        "        APPOSTOPHES = {\"s\" : \"is\", \"re\" : \"are\", \"t\": \"not\", \"ll\":\"will\",\"d\":\"had\",\"ve\":\"have\",\"m\": \"am\"}\n",
        "        words = nltk.tokenize.word_tokenize(msg)\n",
        "        final_words=[]\n",
        "        for word in words:\n",
        "            broken_words=word.split(\"'\")\n",
        "            for single_words in broken_words:\n",
        "                final_words.append(single_words)\n",
        "        reformed = [APPOSTOPHES[word] if word in APPOSTOPHES else word for word in final_words]\n",
        "        reformed = \" \".join(reformed)\n",
        "        return reformed\n",
        "    else:\n",
        "        return msg\n",
        "\n",
        "def remove_punctuations(msg):\n",
        "    if(isinstance(msg, str)):\n",
        "        punctuations = '''!()-[]{};:'\"\\,./?@#$%^&@*_~'''\n",
        "        no_punct = \"\"\n",
        "        for char in msg:\n",
        "            if (char not in punctuations):\n",
        "                no_punct = no_punct + char\n",
        "        return no_punct\n",
        "    else:\n",
        "        return msg\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dtMJBnfFXdvT",
        "colab_type": "code",
        "outputId": "67edbf82-0ea8-4c1b-9900-cda0dc7ae910",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p1D4zTXTXd2m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import nltk\n",
        "from nltk.corpus import wordnet as wn\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "23Aa2K8qXd8b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wnl = WordNetLemmatizer()\n",
        "stop_words = set(stopwords.words('english')) \n",
        "def my_tokeniser(s):\n",
        "    if(isinstance(s, str)):\n",
        "        s = clean_data(s)\n",
        "        s = s.lower()\n",
        "    tokens = nltk.tokenize.word_tokenize(s)\n",
        "    tokens = [t for t in tokens if len(t)>2]\n",
        "    tokens = [wnl.lemmatize(t) for t in tokens]\n",
        "    tokens = [t for t in tokens if t not in stop_words]\n",
        "    return tokens"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qgH-mu_fXd7f",
        "colab_type": "code",
        "outputId": "9dbe6303-94fd-4086-e94b-896ce7c8ee35",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kL9g9LUZXd1T",
        "colab_type": "code",
        "outputId": "b4d93f64-35de-4798-e592-ca1b88ab573d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "nltk.download('wordnet')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gRnJSWyKXduT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LZ9MqGm3Xdov",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PzoNXLmaXdix",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LLjaBBGOXdc0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vmhMnvNbXdWk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fK9xYKeoTzwj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def prepData(text):\n",
        "    # Convert to array\n",
        "    textDataArray = my_tokeniser(text)\n",
        "    print(text)\n",
        "    txdata = [text]\n",
        "    print(textDataArray)\n",
        "    # Convert into list with word ids\n",
        "    # Features = Tokenizer.texts_to_sequences(text,Tokenizer)\n",
        "    # Features = keras.preprocessing.text.text_to_word_sequence(text, filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n', lower=True, split=' ')\n",
        "    #Features = keras.preprocessing.text.one_hot(text, 100, filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n', lower=True, split=' ')\n",
        "\n",
        "    #print(Features)\n",
        "    # Features = Tokenizer.texts_to_sequences(Tokenizer,textDataArray)\n",
        "    # Features = pad_sequences(Features, 20, padding='post')\n",
        "    # tok.fit_on_texts(texts)\n",
        "    # mat_texts = tok.texts_to_matrix(texts,mode='count')\n",
        "    mat_texts = tok.texts_to_matrix(txdata,mode='count')\n",
        "    x_test1 = tok.texts_to_sequences(txdata)\n",
        "    Features = sequence.pad_sequences(x_test1,maxlen=max_len)\n",
        "\n",
        "    # Convert into list with word ids\n",
        "    #Features = Tokenizer.texts_to_sequences(textDataArray,Tokenizer)\n",
        "    #Features = keras.preprocessing.text.text_to_word_sequence(text, filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n', lower=True, split=' ')\n",
        "    # Features = sequence.pad_sequences(mat_texts, 100, padding='post')\n",
        "    \n",
        "    return Features"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3LLR3WOYTzuI",
        "colab_type": "code",
        "outputId": "8d54ad0d-3bf0-44bc-d607-284c59746575",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "message = 'Your account has been hacked. Please call 1-800-0000 to speak with a representative'\n",
        "textTokenizedTest = prepData(message)\n",
        "predict = (m.predict(textTokenizedTest))\n",
        "\n",
        "message1 = 'D/P The School will remain closed from 26.10.2019 to 29.10.2019 on account of Diwali and Bhai Dooj. WISHING YOU A HAPPY DIWALI, AUSPICIOUS GOVERDHAN POOJA AND BHAI DOOJ'\n",
        "textTokenizedTest1 = prepData(message1)\n",
        "predict1 = (m.predict(textTokenizedTest1))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Your account has been hacked. Please call 1-800-0000 to speak with a representative\n",
            "['account', 'ha', 'hacked', 'please', 'call', '180000', 'speak', 'representative']\n",
            "D/P The School will remain closed from 26.10.2019 to 29.10.2019 on account of Diwali and Bhai Dooj. WISHING YOU A HAPPY DIWALI, AUSPICIOUS GOVERDHAN POOJA AND BHAI DOOJ\n",
            "['school', 'remain', 'closed', '26102019', '29102019', 'account', 'diwali', 'bhai', 'dooj', 'wishing', 'happy', 'diwali', 'auspicious', 'goverdhan', 'pooja', 'bhai', 'dooj']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SRp_pcnMYCPS",
        "colab_type": "code",
        "outputId": "21b1a5d7-7bad-44d9-9b4a-60fc405166fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "print(predict)\n",
        "print(predict1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.9840577]]\n",
            "[[1.1923067e-05]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iQwqc1GbYCMp",
        "colab_type": "code",
        "outputId": "c2d87c85-b448-4518-b3d2-2e0b5cbe81d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "textTokenizedTest.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 100)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ruYxWbgjc9KC",
        "colab_type": "code",
        "outputId": "03cdabaf-3104-456d-a9c4-9a0ce86cfbb7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "message = 'Your account has been hacked. Please call 1-800-0000 to speak with a representative'\n",
        "textTokenizedTest = prepData(message)\n",
        "predict2 = (m.predict_classes(textTokenizedTest))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Your account has been hacked. Please call 1-800-0000 to speak with a representative\n",
            "['account', 'ha', 'hacked', 'please', 'call', '180000', 'speak', 'representative']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FfC9CoOGc9Pf",
        "colab_type": "code",
        "outputId": "4fe39894-6faf-40dc-c601-94e33fd0394b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "predict2"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LvGLAxu7c9Tz",
        "colab_type": "code",
        "outputId": "c2834d25-ee00-4aed-fb48-ac7844318477",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "message1 = 'D/P The School will remain closed from 26.10.2019 to 29.10.2019 on account of Diwali and Bhai Dooj. WISHING YOU A HAPPY DIWALI, AUSPICIOUS GOVERDHAN POOJA AND BHAI DOOJ'\n",
        "textTokenizedTest1 = prepData(message1)\n",
        "predict3 = (m.predict_proba(textTokenizedTest1))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "D/P The School will remain closed from 26.10.2019 to 29.10.2019 on account of Diwali and Bhai Dooj. WISHING YOU A HAPPY DIWALI, AUSPICIOUS GOVERDHAN POOJA AND BHAI DOOJ\n",
            "['school', 'remain', 'closed', '26102019', '29102019', 'account', 'diwali', 'bhai', 'dooj', 'wishing', 'happy', 'diwali', 'auspicious', 'goverdhan', 'pooja', 'bhai', 'dooj']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WWQVK0vFc9OJ",
        "colab_type": "code",
        "outputId": "ab6c580d-8822-4828-edf3-781d46dc0c8a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "predict3"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.1923067e-05]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SzbBpqE1c9Ie",
        "colab_type": "code",
        "outputId": "dd30e6ca-0f55-44ba-866c-83552e811524",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "predict4 = m.predict_classes(textTokenizedTest1)\n",
        "predict4"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v3lZx-Oho5bD",
        "colab_type": "code",
        "outputId": "92a2bba3-244a-4608-bfa5-bddde8771de3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "pf4 = np.asscalar(predict4)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zABsTg_sjCkX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tags_reversed = le.get_params(deep=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QoTpmz5RjCp8",
        "colab_type": "code",
        "outputId": "2730f0f4-bb40-4195-c423-a2f9b14fa831",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "tags_reversed"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QszbiBLGjCwc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_integer_mapping(le):\n",
        "    '''\n",
        "    Return a dict mapping labels to their integer values\n",
        "    from an SKlearn LabelEncoder\n",
        "    le = a fitted SKlearn LabelEncoder\n",
        "    '''\n",
        "    res = {}\n",
        "    for cl in le.classes_:\n",
        "        res.update({cl:le.transform([cl])[0]})\n",
        "\n",
        "    return res"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RHzqX_LpjC1v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dic = get_integer_mapping(le)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "npCUdM5njC7L",
        "colab_type": "code",
        "outputId": "c8fd7b42-19ba-46e5-9f71-9aabe8607ce1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "dic"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'ham': 0, 'spam': 1}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F8a7ICh0jC03",
        "colab_type": "code",
        "outputId": "5cea43b5-c573-47dd-90e8-f75d6b07a472",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "pf4"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CO1Cz5Z8jCvd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if(pf4==dic['ham']):\n",
        "  pfpredi = 'ham'\n",
        "else:\n",
        "  pfpredi = 'spam'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SBxUrJKHjCo_",
        "colab_type": "code",
        "outputId": "0c0c8425-7876-43ab-c82a-4f59e01525aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "pfpredi"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'ham'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Z5kSIURjCit",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "message1 = 'D/P The School will remain closed from 26.10.2019 to 29.10.2019 on account of Diwali and Bhai Dooj. WISHING YOU A HAPPY DIWALI, AUSPICIOUS GOVERDHAN POOJA AND BHAI DOOJ'\n",
        "textTokenizedTest1 = prepData(message1)\n",
        "predict3 = (m.predict_proba(textTokenizedTest1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CmRvXw-Ww_4M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cBH3evSrw_9L",
        "colab_type": "code",
        "outputId": "712e5f77-4ae2-490b-a003-57353c592641",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        }
      },
      "source": [
        "message5 = 'Free Hellotune service for 30 days will be activated shortly. Extend validity on Wynk App @wynk.onelink.me/333062766/hello. To stop, call/SMS STOP to 155223'\n",
        "textTokenizedTest5 = prepData(message5)\n",
        "predict5 = (m.predict_proba(textTokenizedTest5))\n",
        "print(predict5)\n",
        "print(np.asscalar(m.predict(textTokenizedTest5)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Free Hellotune service for 30 days will be activated shortly. Extend validity on Wynk App @wynk.onelink.me/333062766/hello. To stop, call/SMS STOP to 155223\n",
            "['free', 'hellotune', 'service', 'day', 'activated', 'shortly', 'extend', 'validity', 'wynk', 'app', 'wynkonelinkme33062766hello', 'stop', 'callsms', 'stop', '155223']\n",
            "[[0.50586855]]\n",
            "0.5058685541152954\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
            "  \"\"\"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "neNHwCPUxAC5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "omtsdPj0xAJV",
        "colab_type": "code",
        "outputId": "ecb79815-2279-4c4e-c434-a6cbcab1af0b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        }
      },
      "source": [
        "message6 = 'CVA \\'19Upload the Video clip/PPT of your working prototype latest by 10/11/19 on AICTE-CVA portal.For further details refer your email or AICTE website.'\n",
        "textTokenizedTest6 = prepData(message6)\n",
        "predict6 = (m.predict_proba(textTokenizedTest6))\n",
        "print(predict6)\n",
        "print(np.asscalar(m.predict(textTokenizedTest6)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CVA '19Upload the Video clip/PPT of your working prototype latest by 10/11/19 on AICTE-CVA portal.For further details refer your email or AICTE website.\n",
            "['cva', '19upload', 'video', 'clipppt', 'working', 'prototype', 'latest', '101119', 'aictecva', 'portalfor', 'detail', 'refer', 'email', 'aicte', 'website']\n",
            "[[0.50293493]]\n",
            "0.5029349327087402\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
            "  \"\"\"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0iNCHykExAB-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQ-Xp8ujw_8K",
        "colab_type": "code",
        "outputId": "55b675a4-da2d-4b79-fdf0-302013c50273",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "message7 = 'Last day to get 50% Off on entire summer collection. Shop online @ Montecarlo.in . Select styles excluded. Easy Refund & Returns'\n",
        "textTokenizedTest7 = prepData(message7)\n",
        "predict7 = (m.predict_proba(textTokenizedTest7))\n",
        "print(predict7)\n",
        "print(np.asscalar(m.predict(textTokenizedTest7)))\n",
        "print(np.asscalar(m.predict_classes(textTokenizedTest7)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Last day to get 50% Off on entire summer collection. Shop online @ Montecarlo.in . Select styles excluded. Easy Refund & Returns\n",
            "['last', 'day', 'get', 'entire', 'summer', 'collection', 'shop', 'online', 'montecarloin', 'select', 'style', 'excluded', 'easy', 'refund', 'return']\n",
            "[[0.50494605]]\n",
            "0.5049460530281067\n",
            "1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
            "  \"\"\"\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_u4cqDSfw_2K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zB6rN9i-SKBC",
        "colab_type": "code",
        "outputId": "f94f06a7-213a-4c59-bfbc-dc3dfe5ae51e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "message8 = 'Good Morning, Gentle Reminder for  TOI presents VC Conclave @Shangri-La Hotel, Ashoka Road, Janpath, Connaught Place, New Delhi today from 10:00AM onwards.'\n",
        "textTokenizedTest8 = prepData(message8)\n",
        "predict8 = (m.predict_proba(textTokenizedTest8))\n",
        "print(predict8)\n",
        "print(np.asscalar(m.predict_classes(textTokenizedTest8)))\n",
        "print(np.asscalar(m.predict(textTokenizedTest8)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Good Morning, Gentle Reminder for  TOI presents VC Conclave @Shangri-La Hotel, Ashoka Road, Janpath, Connaught Place, New Delhi today from 10:00AM onwards.\n",
            "['good', 'morning', 'gentle', 'reminder', 'toi', 'present', 'conclave', 'shangrila', 'hotel', 'ashoka', 'road', 'janpath', 'connaught', 'place', 'new', 'delhi', 'today', '1000am', 'onwards']\n",
            "[[0.5030867]]\n",
            "1\n",
            "0.5030866861343384\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
            "  \"\"\"\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BU1e_uk2xEqx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "le1 = LabelEncoder()\n",
        "tags11 = le1.fit_transform(tags)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dpgo5obb1enp",
        "colab_type": "code",
        "outputId": "b3452d7b-b6e9-4415-8627-634e6b5134f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "get_integer_mapping(le1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'ham': 0, 'spam': 1}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WvssNmhB1lnf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}